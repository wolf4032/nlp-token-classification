{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHAgbdBqIHs5z46X6Ajnzk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# driveのmountとディレクトリの変更"],"metadata":{"id":"Vlqmvhe16YVN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2l9ymug6doy","executionInfo":{"status":"ok","timestamp":1712535537036,"user_tz":-540,"elapsed":29441,"user":{"displayName":"Classification Token","userId":"00971695854121712594"}},"outputId":"b201b9e6-ce23-4641-aa01-0b6206ff5fbb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/local_cuisine_search_app/modules"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqnfPR656e5E","executionInfo":{"status":"ok","timestamp":1712535537037,"user_tz":-540,"elapsed":9,"user":{"displayName":"Classification Token","userId":"00971695854121712594"}},"outputId":"46cc1171-6ab4-40c8-c07f-eedeca490dc1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/local_cuisine_search_app/modules\n"]}]},{"cell_type":"markdown","source":["# import"],"metadata":{"id":"fAxfKN5aLU-x"}},{"cell_type":"code","source":["%%writefile pipeline.py\n","from typing import Dict, List\n","\n","from transformers import BertJapaneseTokenizer, BertForTokenClassification, pipeline\n","from transformers.pipelines.token_classification import TokenClassificationPipeline\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9EACLCNKmdU","executionInfo":{"status":"ok","timestamp":1712537079418,"user_tz":-540,"elapsed":352,"user":{"displayName":"Classification Token","userId":"00971695854121712594"}},"outputId":"d6be59b5-ce86-48a4-f4b1-d874fd72e7b4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing pipeline.py\n"]}]},{"cell_type":"markdown","source":["# 固有表現抽出を行うクラス"],"metadata":{"id":"oP0r9RHYE0GT"}},{"cell_type":"code","source":["%%writefile -a pipeline.py\n","class NaturalLanguageProcessing:\n","    \"\"\"\n","    固有表現を抽出するクラス\n","\n","    model_dirにある言語モデルを使って固有表現抽出パイプラインを作成する\n","    モデルに固有表現を抽出させるメソッドを持つ\n","\n","    Attributes\n","    ----------\n","    _nlp : TokenClassificationPipeline\n","        固有表現抽出パイプライン\n","    \"\"\"\n","    def __init__(self, model_dir: str):\n","        \"\"\"\n","        コンストラクタ\n","\n","        _nlpを作成する\n","\n","        Parameters\n","        ----------\n","        model_dir : str\n","            使用する言語モデルのディレクトリ\n","        \"\"\"\n","        self._nlp = NaturalLanguageProcessing._create(model_dir)\n","\n","    @staticmethod\n","    def _create(model_dir: str) -> TokenClassificationPipeline:\n","        \"\"\"\n","        パイプラインの作成\n","\n","        Parameters\n","        ----------\n","        model_dir : str\n","            使用する言語モデルのディレクトリ\n","\n","        Returns\n","        -------\n","        TokenClassificationPipeline\n","            固有表現抽出パイプライン\n","        \"\"\"\n","        tokenizer = BertJapaneseTokenizer.from_pretrained(model_dir)\n","        model = BertForTokenClassification.from_pretrained(model_dir)\n","\n","        nlp = pipeline(\n","            'token-classification',\n","            model=model,\n","            tokenizer=tokenizer,\n","            aggregation_strategy='simple'\n","        )\n","\n","        return nlp\n","\n","    def classify(self, input: str) -> Dict[str, List[str]]:\n","        \"\"\"\n","        固有表現の抽出\n","\n","        Parameters\n","        ----------\n","        input : str\n","            固有表現抽出対象\n","\n","        Returns\n","        -------\n","        Dict[str, List[str]]\n","            抽出結果の辞書\n","            キーが分類ラベル、バリューがそのラベルの文字列のリスト\n","        \"\"\"\n","        prediction_results:List[Dict[str, str | float | None]] = self._nlp(input)\n","\n","        classified_words = {}\n","        for predict_result in prediction_results:\n","            label = predict_result['entity_group']\n","            word = predict_result['word']\n","\n","            if label not in classified_words:\n","                classified_words[label] = []\n","\n","            classified_words[label].append(word.replace(' ', ''))\n","\n","        return classified_words\n","\n","    def classify_and_show(self, input: str) -> Dict[str, List[str]]:\n","        \"\"\"\n","        固有表現の抽出と表示\n","\n","        Parameters\n","        ----------\n","        input : str\n","            固有表現抽出対象\n","\n","        Returns\n","        -------\n","        Dict[str, List[str]]\n","            抽出結果の辞書\n","            キーが分類ラベル、バリューがそのラベルの文字列のリスト\n","        \"\"\"\n","        classified_words = self.classify(input)\n","\n","        for label, words in classified_words.items():\n","            print(f'{label: <10} {\"、\".join(words)}')\n","\n","        return classified_words\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"959KVDqZE8_m","executionInfo":{"status":"ok","timestamp":1712537080437,"user_tz":-540,"elapsed":6,"user":{"displayName":"Classification Token","userId":"00971695854121712594"}},"outputId":"ffc3b3d5-be79-429c-d546-43ac4902aeed"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Appending to pipeline.py\n"]}]}]}